{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYT5NXV-2eXr"
      },
      "source": [
        "In this assignment, you will be implementing a GPT model and train it using CLM objective.\n",
        " * If you get stuck at something or need more clarrifications, you may refer to : https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n",
        "\n",
        " * We will be using ReLU activation function instead of GELU.\n",
        "\n",
        " * As usual, let us install the required libraries\n",
        "\n",
        " * **Note** that if you are not getting the exact loss values as mentioned in this notebook, that is absolutely fine. Just see whether your implementation overfits the given toy-and-tiny paragraph!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdKopIVVtzKx"
      },
      "source": [
        "# Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HF0ap-B02CW7",
        "outputId": "a567c78f-674f-46e6-89b6-d667b8b0df01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchdata==0.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.6.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchdata==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchdata==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchdata==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchdata==0.6.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchdata==0.6.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchdata==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchdata==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchdata==0.6.0) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchdata==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchdata==0.6.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchdata==0.6.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.0->torchdata==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.0->torchdata==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: portalocker==2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.0.0)\n",
            "Requirement already satisfied: pywin32!=226 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from portalocker==2.0.0) (305.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata==0.6.0\n",
        "!pip install portalocker==2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37SOAt7OE8pW"
      },
      "source": [
        "* See [here](https://github.com/pytorch/text) for compatability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amMg7VeGEnui",
        "outputId": "fae79843-fd19-4786-ea52-2bf0935f2334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.15.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.15.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchtext==0.15.1) (4.65.0)\n",
            "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchtext==0.15.1) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchtext==0.15.1) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchtext==0.15.1) (0.6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchtext==0.15.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchtext==0.15.1) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchtext==0.15.1) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchtext==0.15.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchtext==0.15.1) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchtext==0.15.1) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->torchtext==0.15.1) (2024.2.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm->torchtext==0.15.1) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torchtext==0.15.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFnTb-YGtudi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCbW1AUlZsoO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "#text lib\n",
        "import torchtext\n",
        "\n",
        "# tokenizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "#build vocabulary\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# get input_ids (numericalization)\n",
        "from torchtext.transforms import VocabTransform\n",
        "\n",
        "# get embeddings\n",
        "from torch.nn import Embedding\n",
        "\n",
        "from  pprint import pprint\n",
        "from yaml import safe_load\n",
        "import copy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjjPjidG6kr1",
        "outputId": "955cbf4b-2795-41f4-d09b-ef3fda807a3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wTjUVQRaoqI"
      },
      "source": [
        "# Load the dataset for LM modeling\n",
        "\n",
        " * We use a simple tokenizer and put"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aWB84SAN00b"
      },
      "outputs": [],
      "source": [
        "batch_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBzIVx8u5VQU"
      },
      "outputs": [],
      "source": [
        "class Tokenizer(object):\n",
        "\n",
        "  def __init__(self,text):\n",
        "    self.text = text\n",
        "    self.word_tokenizer = get_tokenizer(tokenizer=\"basic_english\",language='en')\n",
        "    self.vocab_size = None\n",
        "\n",
        "  def get_tokens(self):\n",
        "    for sentence in self.text.strip().split('\\n'):\n",
        "      yield self.word_tokenizer(sentence)\n",
        "\n",
        "  def build_vocab(self):\n",
        "    v = build_vocab_from_iterator(self.get_tokens(),\n",
        "                                  min_freq=1,specials=['<unk>','<start>','<end>'])\n",
        "    v.set_default_index(v['<unk>']) # index of OOV\n",
        "    self.vocab_size = len(v)\n",
        "    return v\n",
        "\n",
        "  def token_ids(self):\n",
        "    v = self.build_vocab()\n",
        "    vt = VocabTransform(v)\n",
        "    num_tokens = len(self.word_tokenizer(self.text))\n",
        "    max_seq_len = np.ceil(num_tokens/batch_size)\n",
        "    data = torch.zeros(size=(1,num_tokens))\n",
        "    data = vt(self.word_tokenizer(self.text))\n",
        "    data = torch.tensor(data,dtype=torch.int64)\n",
        "    return data.reshape(batch_size,torch.tensor(max_seq_len,dtype=torch.int64))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE1L07Z-AoNz"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Best known for the invention of Error Correcting Codes, he was a true polymath who applied his mathematical and problem-solving skills to numerous disciplines.\n",
        "Reflecting on the significant benefits I received from Hamming, I decided to develop a tribute to his legacy. There has not been a previous biography of Hamming, and the few articles about him restate known facts and assumptions and leave us with open questions.\n",
        "One thought drove me as I developed this legacy project: An individual's legacy is more than a list of their attempts and accomplishments. Their tribute should also reveal the succeeding generations they inspired and enabled and what each attempted and achieved.\n",
        "This book is a unique genre containing my version of a biography that intertwines the story \"of a life\" and a multi-player memoir with particular events and turning points recalled by those, including me, who he inspired and enabled.\n",
        "Five years of research uncovered the people, places, opportunities, events, and influences that shaped Hamming. I discovered unpublished information, stories, photographs, videos, and personal remembrances to chronicle his life, which helped me put Hamming's\n",
        "legacy in the context I wanted.The result demonstrates many exceptional qualities, including his noble pursuit of excellence and helping others. Hamming paid attention to the details, his writings continue to influence, and his guidance is a timeless gift to the world.\n",
        "This biography is part of \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA9GqXl8QvLo",
        "outputId": "d50447b0-bba9-4c40-df63-4af584a328a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Best known for the invention of Error Correcting Codes, he was a true polymath who applied his mathematical and problem-solving skills to numerous disciplines',\n",
              " '\\nReflecting on the significant benefits I received from Hamming, I decided to develop a tribute to his legacy',\n",
              " ' There has not been a previous biography of Hamming, and the few articles about him restate known facts and assumptions and leave us with open questions',\n",
              " \"\\nOne thought drove me as I developed this legacy project: An individual's legacy is more than a list of their attempts and accomplishments\",\n",
              " ' Their tribute should also reveal the succeeding generations they inspired and enabled and what each attempted and achieved',\n",
              " '\\nThis book is a unique genre containing my version of a biography that intertwines the story \"of a life\" and a multi-player memoir with particular events and turning points recalled by those, including me, who he inspired and enabled',\n",
              " '\\nFive years of research uncovered the people, places, opportunities, events, and influences that shaped Hamming',\n",
              " \" I discovered unpublished information, stories, photographs, videos, and personal remembrances to chronicle his life, which helped me put Hamming's\\nlegacy in the context I wanted\",\n",
              " 'The result demonstrates many exceptional qualities, including his noble pursuit of excellence and helping others',\n",
              " ' Hamming paid attention to the details, his writings continue to influence, and his guidance is a timeless gift to the world',\n",
              " '\\nThis biography is part of ']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the text by '.'\n",
        "sentences = text.split('.')\n",
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OD9gBdaBHs1"
      },
      "outputs": [],
      "source": [
        "Tk = Tokenizer(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTz7eGsSFK24",
        "outputId": "9dfc0deb-9016-4ac1-cdcb-0946b4ee7223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 26])\n",
            "tensor([[ 46,  24,  70,   6,  86,   8,  64,  54,  50,   3,  21, 149,   7, 140,\n",
            "         111,  30,  37,  10,  90,   4, 113, 130,   9,  97,  60,   5],\n",
            "        [121,  98,   6, 129,  45,  12, 120,  71,  11,   3,  12,  55,   9,  58,\n",
            "           7,  29,   9,  10,  14,   5, 135,  76,  96,  44,   7, 112],\n",
            "        [ 15,   8,  11,   3,   4,   6,  68,  38,  32,  79, 124,  24,  67,   4,\n",
            "          40,   4,  87, 145,  31, 100, 118,   5,  99, 138,  62,  16],\n",
            "        [ 39,  12,  59,  17,  14, 114,  36,  81,  18,  26,  14,  13,  92, 134,\n",
            "           7,  88,   8,  28,  42,   4,  33,   5,  28,  29, 128,  35],\n",
            "        [126,   6, 133,  72, 136,  23,   4,  19,   4, 150,  63,  41,   4,  34,\n",
            "           5,  17,  47,  13,   7, 143,  73,  51,  94, 146,   8,   7],\n",
            "        [ 15,  27,  85,   6, 132,   8,   7,  25,   4,   7,  93,  91,  31, 105,\n",
            "          20,   4, 141, 110, 119,  48, 137,   3,  22,  16,   3,  30],\n",
            "        [ 21,  23,   4,  19,   5,  69, 154,   8, 123, 142,   6, 106,   3, 109,\n",
            "           3, 101,   3,  20,   3,   4,  83,  27, 127,  11,   5,  12],\n",
            "        [ 61, 144,  84,   3, 131,   3, 108,   3, 147,   3,   4, 107, 122,   9,\n",
            "          49,  10,  25,   3, 151,  77,  16, 116,  11,  18,  26,  14],\n",
            "        [ 80,   6,  52,  12, 148,   5,   6, 125,  56,  89,  66, 117,   3,  22,\n",
            "          10,  95, 115,   8,  65,   4,  78, 102,   5,  11, 103,  43],\n",
            "        [  9,   6,  57,   3,  10, 153,  53,   9,  82,   3,   4,  10,  75,  13,\n",
            "           7, 139,  74,   9,   6, 152,   5,  17,  15,  13, 104,   8]])\n"
          ]
        }
      ],
      "source": [
        "x_raw = Tk.token_ids()\n",
        "print(x_raw.shape)\n",
        "print(x_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToL6j7ECOEIC",
        "outputId": "39fa9f5f-7c45-4ed1-eaa3-8fd2c46c856e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<unk>', '<start>', '<end>', ',', 'and', '.', 'the', 'a', 'of', 'to']\n"
          ]
        }
      ],
      "source": [
        "# let us display the first 10 tokens of the vocabulary\n",
        "vocab = Tk.build_vocab()\n",
        "pprint(vocab.vocab.get_itos()[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf5-MO_MRi64",
        "outputId": "a05f6950-9571-48ef-83fc-5747a600c9ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "155 ['<unk>', '<start>', '<end>', ',', 'and', '.', 'the', 'a', 'of', 'to', 'his', 'hamming', 'i', 'is', 'legacy', 'biography', 'me', 'this', \"'\", 'enabled', 'events', 'he', 'including', 'inspired', 'known', 'life', 's', 'that', 'their', 'tribute', 'who', 'with', 'about', 'accomplishments', 'achieved', 'also', 'an', 'applied', 'articles', 'as', 'assumptions', 'attempted', 'attempts', 'attention', 'been', 'benefits', 'best', 'book', 'by', 'chronicle', 'codes', 'containing', 'context', 'continue', 'correcting', 'decided', 'demonstrates', 'details', 'develop', 'developed', 'disciplines', 'discovered', 'drove', 'each', 'error', 'excellence', 'exceptional', 'facts', 'few', 'five', 'for', 'from', 'generations', 'genre', 'gift', 'guidance', 'has', 'helped', 'helping', 'him', 'in', 'individual', 'influence', 'influences', 'information', 'intertwines', 'invention', 'leave', 'list', 'many', 'mathematical', 'memoir', 'more', 'multi-player', 'my', 'noble', 'not', 'numerous', 'on', 'one', 'open', 'opportunities', 'others', 'paid', 'part', 'particular', 'people', 'personal', 'photographs', 'places', 'points', 'polymath', 'previous', 'problem-solving', 'project', 'pursuit', 'put', 'qualities', 'questions', 'recalled', 'received', 'reflecting', 'remembrances', 'research', 'restate', 'result', 'reveal', 'shaped', 'should', 'significant', 'skills', 'stories', 'story', 'succeeding', 'than', 'there', 'they', 'those', 'thought', 'timeless', 'true', 'turning', 'uncovered', 'unique', 'unpublished', 'us', 'version', 'videos', 'wanted', 'was', 'what', 'which', 'world', 'writings']\n"
          ]
        }
      ],
      "source": [
        "print(len(vocab), vocab.get_itos()[0:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs00A32ieNJp"
      },
      "source": [
        "* Create the input_ids and Labels from the raw input sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dCg4PYfaXhP",
        "outputId": "21de7630-505a-4c93-e7f0-69bf335fd42a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start> best known for the invention of error correcting codes , he was a true polymath who applied his mathematical and problem-solving skills to numerous disciplines . <end>\n"
          ]
        }
      ],
      "source": [
        "bs,raw_seq_len = x_raw.shape\n",
        "x = torch.empty(size=(bs,raw_seq_len+2),dtype=torch.int64)\n",
        "x[:,1:-1] =x_raw\n",
        "\n",
        "# insert the index of special tokens\n",
        "x[:,0] = torch.full(size=(1,batch_size),fill_value=vocab.vocab.get_stoi()['<start>'])\n",
        "x[:,-1] = torch.full(size=(1,batch_size),fill_value=vocab.vocab.get_stoi()['<end>'])\n",
        "\n",
        "#Quickly check implem\n",
        "vocab = Tk.build_vocab()\n",
        "words = []\n",
        "for idx in x[0,:]:\n",
        "  words.append(vocab.vocab.get_itos()[idx.item()])\n",
        "print(' '.join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-Y0R3FSfEex"
      },
      "outputs": [],
      "source": [
        "# labels are just the input_ids shifted by right\n",
        "bs,seq_len = x.shape\n",
        "y = torch.empty(size=(bs,seq_len),dtype=torch.int64)\n",
        "y[:,0:-1] = copy.deepcopy(x[:,1:])\n",
        "\n",
        "#ignore the index of padded tokens while computing loss\n",
        "y[:,-1] = torch.full(size=(1,batch_size),fill_value=-100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGbKIKxp-Erw",
        "outputId": "7fd999a9-69f4-4dc0-e1a0-d3c7373b3903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial input is tensor([[  1,  46,  24,  70,   6,  86,   8,  64,  54,  50,   3,  21, 149,   7,\n",
            "         140, 111,  30,  37,  10,  90,   4, 113, 130,   9,  97,  60,   5,   2],\n",
            "        [  1, 121,  98,   6, 129,  45,  12, 120,  71,  11,   3,  12,  55,   9,\n",
            "          58,   7,  29,   9,  10,  14,   5, 135,  76,  96,  44,   7, 112,   2],\n",
            "        [  1,  15,   8,  11,   3,   4,   6,  68,  38,  32,  79, 124,  24,  67,\n",
            "           4,  40,   4,  87, 145,  31, 100, 118,   5,  99, 138,  62,  16,   2],\n",
            "        [  1,  39,  12,  59,  17,  14, 114,  36,  81,  18,  26,  14,  13,  92,\n",
            "         134,   7,  88,   8,  28,  42,   4,  33,   5,  28,  29, 128,  35,   2],\n",
            "        [  1, 126,   6, 133,  72, 136,  23,   4,  19,   4, 150,  63,  41,   4,\n",
            "          34,   5,  17,  47,  13,   7, 143,  73,  51,  94, 146,   8,   7,   2],\n",
            "        [  1,  15,  27,  85,   6, 132,   8,   7,  25,   4,   7,  93,  91,  31,\n",
            "         105,  20,   4, 141, 110, 119,  48, 137,   3,  22,  16,   3,  30,   2],\n",
            "        [  1,  21,  23,   4,  19,   5,  69, 154,   8, 123, 142,   6, 106,   3,\n",
            "         109,   3, 101,   3,  20,   3,   4,  83,  27, 127,  11,   5,  12,   2],\n",
            "        [  1,  61, 144,  84,   3, 131,   3, 108,   3, 147,   3,   4, 107, 122,\n",
            "           9,  49,  10,  25,   3, 151,  77,  16, 116,  11,  18,  26,  14,   2],\n",
            "        [  1,  80,   6,  52,  12, 148,   5,   6, 125,  56,  89,  66, 117,   3,\n",
            "          22,  10,  95, 115,   8,  65,   4,  78, 102,   5,  11, 103,  43,   2],\n",
            "        [  1,   9,   6,  57,   3,  10, 153,  53,   9,  82,   3,   4,  10,  75,\n",
            "          13,   7, 139,  74,   9,   6, 152,   5,  17,  15,  13, 104,   8,   2]]) and its shape is torch.Size([10, 28])\n",
            "Expected output is tensor([[  46,   24,   70,    6,   86,    8,   64,   54,   50,    3,   21,  149,\n",
            "            7,  140,  111,   30,   37,   10,   90,    4,  113,  130,    9,   97,\n",
            "           60,    5,    2, -100],\n",
            "        [ 121,   98,    6,  129,   45,   12,  120,   71,   11,    3,   12,   55,\n",
            "            9,   58,    7,   29,    9,   10,   14,    5,  135,   76,   96,   44,\n",
            "            7,  112,    2, -100],\n",
            "        [  15,    8,   11,    3,    4,    6,   68,   38,   32,   79,  124,   24,\n",
            "           67,    4,   40,    4,   87,  145,   31,  100,  118,    5,   99,  138,\n",
            "           62,   16,    2, -100],\n",
            "        [  39,   12,   59,   17,   14,  114,   36,   81,   18,   26,   14,   13,\n",
            "           92,  134,    7,   88,    8,   28,   42,    4,   33,    5,   28,   29,\n",
            "          128,   35,    2, -100],\n",
            "        [ 126,    6,  133,   72,  136,   23,    4,   19,    4,  150,   63,   41,\n",
            "            4,   34,    5,   17,   47,   13,    7,  143,   73,   51,   94,  146,\n",
            "            8,    7,    2, -100],\n",
            "        [  15,   27,   85,    6,  132,    8,    7,   25,    4,    7,   93,   91,\n",
            "           31,  105,   20,    4,  141,  110,  119,   48,  137,    3,   22,   16,\n",
            "            3,   30,    2, -100],\n",
            "        [  21,   23,    4,   19,    5,   69,  154,    8,  123,  142,    6,  106,\n",
            "            3,  109,    3,  101,    3,   20,    3,    4,   83,   27,  127,   11,\n",
            "            5,   12,    2, -100],\n",
            "        [  61,  144,   84,    3,  131,    3,  108,    3,  147,    3,    4,  107,\n",
            "          122,    9,   49,   10,   25,    3,  151,   77,   16,  116,   11,   18,\n",
            "           26,   14,    2, -100],\n",
            "        [  80,    6,   52,   12,  148,    5,    6,  125,   56,   89,   66,  117,\n",
            "            3,   22,   10,   95,  115,    8,   65,    4,   78,  102,    5,   11,\n",
            "          103,   43,    2, -100],\n",
            "        [   9,    6,   57,    3,   10,  153,   53,    9,   82,    3,    4,   10,\n",
            "           75,   13,    7,  139,   74,    9,    6,  152,    5,   17,   15,   13,\n",
            "          104,    8,    2, -100]]) and its shape is torch.Size([10, 28])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Initial input is {x} and its shape is {x.shape}\")\n",
        "print(f\"Expected output is {y} and its shape is {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8-18UlZ2ES7"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kgKn1Emakah",
        "outputId": "b827fa2a-95df-4a05-ab93-105e28ac8656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size is 155, seq_len is 28, embed_dim and dmodel is 32, dq, dk and dv are 4, no. of heads are8, dff is 128\n"
          ]
        }
      ],
      "source": [
        "vocab_size = Tk.vocab_size\n",
        "seq_len = x.shape[1]\n",
        "embed_dim = 32\n",
        "dmodel = embed_dim\n",
        "dq = torch.tensor(4)\n",
        "dk = torch.tensor(4)\n",
        "dv = torch.tensor(4)\n",
        "heads = torch.tensor(8)\n",
        "d_ff = 4*dmodel\n",
        "print(f\"Vocab size is {vocab_size}, seq_len is {seq_len}, embed_dim and dmodel is {dmodel}, dq, dk and dv are {dq}, no. of heads are{heads}, dff is {d_ff}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyQlw_Q9OLFT"
      },
      "source": [
        "* Define all the sub-layers (mhma,ffn) in the transformer blocks\n",
        "* Seed for $W_Q,W_K,W_V,W_O$, 43, 44 and 45, 46, respectively\n",
        "* Seed for ffn $W_1,W_2$,  47 and 48. There are no biases\n",
        "* Seed for output layer 49"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIL2wDtuSWOP"
      },
      "outputs": [],
      "source": [
        "class MHMA(nn.Module):\n",
        "    def __init__(self, d_model, dq, dk, dv, heads):\n",
        "        super(MHMA, self).__init__()\n",
        "\n",
        "        self.d_model = d_model  # Model dimension (output dimension)\n",
        "        self.heads = heads  # Number of attention heads\n",
        "        self.dq = dq  # Query dimension per head\n",
        "        self.dk = dk  # Key dimension per head\n",
        "        self.dv = dv  # Value dimension per head\n",
        "\n",
        "        # Initialize the weight matrices\n",
        "        self.W_q = nn.Parameter(torch.randn((heads, d_model, dq), generator=torch.manual_seed(43)))\n",
        "        self.W_k = nn.Parameter(torch.randn((heads, d_model, dk), generator=torch.manual_seed(44)))\n",
        "        self.W_v = nn.Parameter(torch.randn((heads, d_model, dv), generator=torch.manual_seed(45)))\n",
        "        self.W_o = nn.Parameter(torch.randn((d_model, d_model), generator=torch.manual_seed(46)))\n",
        "\n",
        "        # Xavier initialization\n",
        "        nn.init.xavier_uniform_(self.W_q)\n",
        "        nn.init.xavier_uniform_(self.W_k)\n",
        "        nn.init.xavier_uniform_(self.W_v)\n",
        "        nn.init.xavier_uniform_(self.W_o)\n",
        "\n",
        "        # Attention head size\n",
        "        self.attn_head_size = self.dk  # Typically dk == dq == dv per head\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        BS, T, _ = Q.shape\n",
        "        #print(f\"Q shape: {Q.shape}, K shape: {K.shape}, V shape: {V.shape}\")  # Debugging line\n",
        "        Q = torch.einsum('BTM, HMQ -> BHTQ', Q, self.W_q)\n",
        "        K = torch.einsum('BTM, HMK -> BHTK', K, self.W_k)\n",
        "        V = torch.einsum('BTM, HMV -> BHTV', V, self.W_v)\n",
        "        #print(f\"Transformed Q shape: {Q.shape}, K shape: {K.shape}, V shape: {V.shape}\")  # Debugging line\n",
        "        # Handle the case when mask is None during inference\n",
        "        if mask is not None:\n",
        "            #print(f\"Mask in use and its shape is {mask.shape}\")\n",
        "            attn_score = torch.matmul(F.softmax((torch.matmul(Q, torch.transpose(K, -2, -1)) + mask) / math.sqrt(self.dq), dim=-1), V)\n",
        "        else:\n",
        "            #print(\" No Masking\")\n",
        "            attn_score = torch.matmul(F.softmax(torch.matmul(Q, torch.transpose(K, -2, -1)) / math.sqrt(self.dq), dim=-1), V)\n",
        "        #print(f\"Attention score shappe is {attn_score.shape}\")\n",
        "        combined_attn = attn_score.permute(0, 2, 1, 3).contiguous().view(BS, T, -1)\n",
        "        out = torch.matmul(combined_attn, self.W_o)\n",
        "        #print(f\"Final output from MHMA shape is {out.shape}\")\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYbjvGc-SXlR"
      },
      "outputs": [],
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, dmodel, d_ff):\n",
        "        super(FFN, self).__init__()\n",
        "        torch.manual_seed(47)\n",
        "        self.W1 = nn.Linear(dmodel, d_ff, bias=False)\n",
        "        torch.manual_seed(48)\n",
        "        self.W2 = nn.Linear(d_ff, dmodel, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.W2(F.relu(self.W1(x)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20yIrgtkSbEv"
      },
      "outputs": [],
      "source": [
        "class PredictionHead(nn.Module):\n",
        "    def __init__(self, dmodel, vocab_size):\n",
        "        super(PredictionHead, self).__init__()\n",
        "        torch.manual_seed(49)\n",
        "        self.proj = nn.Linear(dmodel, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.proj(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKNRBf6XSz1h"
      },
      "outputs": [],
      "source": [
        "class PositionalHead(nn.Module):\n",
        "    def __init__(self, dmodel, max_seq_len=512):\n",
        "        super(PositionalHead, self).__init__()\n",
        "        self.dmodel = dmodel\n",
        "\n",
        "        # Compute positional encodings once for all positions\n",
        "        pe = torch.zeros(max_seq_len, dmodel)\n",
        "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, dmodel, 2).float() * (-torch.log(torch.tensor(10000.0)) / dmodel))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3seYE0G0Vwyk"
      },
      "outputs": [],
      "source": [
        "### Creating mask for training\n",
        "mask = (torch.triu(torch.ones(seq_len,seq_len)) == 1).transpose(0,1)\n",
        "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "#print(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z_eWhYUz4rQ"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, dmodel, dq, dk, dv, d_ff, heads):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.mhma = MHMA(dmodel, dq, dk, dv, heads)  # Masked MHMA\n",
        "        self.layer_norm_1 = nn.LayerNorm(dmodel)\n",
        "        self.ffn = FFN(dmodel, d_ff)\n",
        "        self.layer_norm_2 = nn.LayerNorm(dmodel)\n",
        "\n",
        "    def forward(self, dec_rep, mask):\n",
        "        \"\"\"\n",
        "        dec_rep: (batch_size, seq_len, dmodel)\n",
        "        \"\"\"\n",
        "        # Multi-Head Masked Attention\n",
        "        mhma_output = self.mhma(dec_rep,dec_rep, dec_rep,  mask)\n",
        "        # Add & Norm\n",
        "        x = self.layer_norm_1(dec_rep + mhma_output)\n",
        "\n",
        "        # Feed-Forward Network\n",
        "        ffn_output = self.ffn(x)\n",
        "        # Add & Norm\n",
        "        out = self.layer_norm_2(x + ffn_output)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuaoeZtd0htC"
      },
      "outputs": [],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, seed=70):\n",
        "        super(Embed, self).__init__()\n",
        "\n",
        "        # Set the seed for reproducibility\n",
        "        torch.manual_seed(70)\n",
        "\n",
        "        # Define the embedding layer\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)  # Embedding for converting tokens to vectors\n",
        "\n",
        "        # Initialize the embedding weights using the seed\n",
        "        #nn.init.normal_(self.embed.weight, mean=0, std=0.1)  # You can use any initialization method here\n",
        "\n",
        "        # Define the positional encoding layer\n",
        "        self.pe = PositionalHead(embed_dim)  # Positional encoding to inject position information\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply embedding and then positional encoding\n",
        "        out = self.pe(self.embed(x))  # First get the embeddings, then apply positional encoding\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zufd26qUkLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yma_Vbc0k9n"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,dmodel,dq,dk,dv,d_ff,heads,num_layers=1):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.embed_lookup = Embed(vocab_size,embed_dim)\n",
        "    self.dec_layers = nn.ModuleList(copy.deepcopy(DecoderLayer(dmodel,dq,dk,dv,d_ff,heads)) for i in range(num_layers))\n",
        "    self.predict = PredictionHead(dmodel,vocab_size)\n",
        "\n",
        "  def forward(self,input_ids, mask):\n",
        "    out = self.embed_lookup(input_ids)\n",
        "    for dec_layer in self.dec_layers:\n",
        "      out = dec_layer(out, mask)\n",
        "    out = self.predict(out)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M62_C8zS06ya"
      },
      "outputs": [],
      "source": [
        "model = Decoder(vocab_size,dmodel,dq,dk,dv,d_ff,heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4y0aNcr2j1e"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uhXU0ae2rxU"
      },
      "outputs": [],
      "source": [
        "def train(input_ids, labels, epochs=1000):\n",
        "    # For recording loss if needed for plotting or diagnostics\n",
        "    loss_trace = []\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        #model.train()  # Ensure the model is in training mode\n",
        "\n",
        "        # Forward pass: Get the model output\n",
        "        out = model(input_ids, mask=mask)\n",
        "\n",
        "        # Compute the loss (cross-entropy between predicted and actual labels)\n",
        "        loss = criterion(out.view(-1, vocab_size), labels.view(-1))  # Flatten for cross-entropy\n",
        "        #print(f\"Loss now is {loss}\")\n",
        "        loss_trace.append(loss.item())\n",
        "\n",
        "        # Backward pass: Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zero gradients for the next step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Optionally print the loss every 100 epochs\n",
        "        #if (epoch + 1) % 100 == 0:\n",
        "            #print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    return loss_trace\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHKeW38t2w4p"
      },
      "outputs": [],
      "source": [
        "# run the model for 10K epochs\n",
        "loss_trace=train(x,y,10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPQQ__PQ6RVd",
        "outputId": "d132c3ce-eae2-43c3-ee1e-a6a5130ae74c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0861978530883789\n"
          ]
        }
      ],
      "source": [
        "print(loss_trace[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Sti5BtU03d"
      },
      "source": [
        "The loss is about 0.09 after 10K epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "miXVf09Y59ej",
        "outputId": "b28dd24f-f6d1-47e7-89ac-87595503c367"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(loss_trace):\n",
        "    # Create a plot of loss over epochs\n",
        "    plt.plot(loss_trace, label='Training Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming loss_trace is the list of loss values returned by your train function\n",
        "plot_loss(loss_trace)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSHVHX4J40eS"
      },
      "source": [
        "# Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcTrU5CSuujt"
      },
      "outputs": [],
      "source": [
        "#### Not using any mask during inference\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(model, prompt='<start>', max_words=25):\n",
        "    model.eval()\n",
        "\n",
        "    # Convert the list of tokens to token ids directly\n",
        "    input_ids = torch.tensor([vocab[token] for token in prompt], dtype=torch.long).unsqueeze(0)  # Shape: [1, seq_len]\n",
        "\n",
        "    # Start with the current input as the prompt\n",
        "    generated_ids = input_ids.clone()  # This keeps track of all the generated tokens\n",
        "    current_input = input_ids  # Initialize the model input as the prompt\n",
        "\n",
        "    # Step 2: Generate the sequence token by token\n",
        "    for i in range(max_words):\n",
        "        # Feed the current input into the model to get the output logits\n",
        "        logits = model(current_input, mask=None)  # Shape: [1, seq_len, vocab_size]\n",
        "\n",
        "        # Get the logits of the last token in the sequence to predict the next token\n",
        "        next_token_logits = logits[:, -1, :]  # Shape: [1, vocab_size]\n",
        "\n",
        "\n",
        "\n",
        "#When we use probabilities and torch.multinomilal, everytime it picks up a different token\n",
        "#and its not deterministic'''\n",
        "         # Convert logits to probabilities using softmax\n",
        "        #probabilities = torch.softmax(next_token_logits, dim=-1)  # Shape: [1, vocab_size]\n",
        "\n",
        "\n",
        "        # Sample a token from the probability distribution\n",
        "        #next_token_id = torch.multinomial(probabilities, num_samples=1)  # Shape: [1, 1]\n",
        "\n",
        "        next_token_id = torch.argmax(next_token_logits, dim=-1, keepdim=True)  # Use argmax instead of sampling\n",
        "\n",
        "\n",
        "        # Append the predicted token to the sequence\n",
        "        generated_ids = torch.cat([generated_ids, next_token_id], dim=1)  # Shape: [1, seq_len + 1]\n",
        "\n",
        "        # Update the input for the next prediction (using the entire generated sequence)\n",
        "        current_input = generated_ids  # Use the entire sequence of generated tokens\n",
        "\n",
        "        # Optionally stop if <end> token is generated\n",
        "        if next_token_id.item() == vocab['<end>']:\n",
        "            break  # Stop if <end> token is generated\n",
        "\n",
        "    # Convert the generated token IDs back to words (excluding <start>)\n",
        "    # Convert the generated token IDs back to words, excluding both <start> and <end>\n",
        "    generated_words = [\n",
        "        vocab.lookup_token(id.item()) for id in generated_ids[0]\n",
        "        if id.item() not in [vocab['<start>'], vocab['<end>']]\n",
        "    ]\n",
        "    return ' '.join(generated_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6KXbgDuku-DN",
        "outputId": "ec553d9d-bbf9-4bcf-9422-970c0dd7a4c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<unk> s <unk> a <unk> <unk> <unk> , is more than a to influence , and . his guidance is a unique genre containing my version of'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model, prompt='<start>', max_words=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTaqoJ_2VDDa"
      },
      "source": [
        "* Note the model has memorized the sentence from the training set. Given the start token, if your implementation reproduce a sentence as is in the training set, then your implementation is likely to be correct.\n",
        "* Suppose the prompt is `<start> best known`, then we expect the model to produce the first sentence as is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2N_Shu7TXjAT",
        "outputId": "63bb49a3-8890-4b0c-8c4d-518f383ad75c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'best known for the invention of error correcting codes , he was a true polymath who applied his mathematical and problem-solving skills to numerous disciplines .'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model,prompt=['<start>','best','known'],max_words=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1hK47T5X2fY"
      },
      "source": [
        "* Change the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q6_WM1K2X7qZ",
        "outputId": "e4fd6cfc-40b2-4ad6-b40c-aac257085c1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'reflecting on the significant benefits i received from hamming , i decided to develop a tribute to his legacy . there has not been a previous'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model,prompt=['<start>','reflecting','on'],max_words=25)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}