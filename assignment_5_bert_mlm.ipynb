{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* In this assignment you will be implementing an encoder model that uses just **Masked Language Modelling (MLM)** objective.\n",
        "* We will use a simple BERT with the following modifications\n",
        "  * We just use MLM (just masking words) and **skip** NSP (Next Sentence Prediction) objective\n",
        "  * Therefore, we won't use [CLS] token\n",
        "* Again, it is absolutely fine if your loss value does not match with the one given here.\n",
        "* Just ensure that the model overfits the training data\n",
        "* You may increase the size of the training data if you want to test your implementation. In that case, we recommend you to use the tokenizer library from Hugging face\n",
        "\n"
      ],
      "metadata": {
        "id": "1-RvnrMa1aBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "MYTmQEKOdNas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cHiReOoRT-7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7138010d-42f7-4107-e51c-edaa6fccf813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdata==0.6.0\n",
            "  Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (919 bytes)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0) (2.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0) (2.32.3)\n",
            "Collecting torch==2.0.0 (from torchdata==0.6.0)\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchdata==0.6.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchdata==0.6.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata==0.6.0) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchdata==0.6.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchdata==0.6.0) (1.3.0)\n",
            "Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0 triton-2.0.0\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.0.0\n",
            "Collecting torchtext==0.15.1\n",
            "  Downloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (0.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n",
            "Downloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.15.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata==0.6.0 # to be compatible with torch 2.0\n",
        "!pip install portalocker==2.0.0\n",
        "!pip install -U torchtext==0.15.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Imports"
      ],
      "metadata": {
        "id": "MxKr-cWAdQ3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "#text lib\n",
        "import torchtext\n",
        "\n",
        "# tokenizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "#build vocabulary\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# get input_ids (numericalization)\n",
        "from torchtext.transforms import VocabTransform\n",
        "\n",
        "# get embeddings\n",
        "from torch.nn import Embedding\n",
        "\n",
        "from  pprint import pprint\n",
        "from yaml import safe_load\n",
        "import copy\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kBtpv-ildSLk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "yqPv7AWKfdUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f652a1fd-b3fc-429e-d997-56716d128b24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize the given text"
      ],
      "metadata": {
        "id": "Qloiz5rGfvA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10"
      ],
      "metadata": {
        "id": "-uEjm4IBfv_g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer(object):\n",
        "\n",
        "  def __init__(self,text):\n",
        "    self.text = text\n",
        "    self.word_tokenizer = get_tokenizer(tokenizer=\"basic_english\",language='en')\n",
        "    self.vocab_size = None\n",
        "\n",
        "  def get_tokens(self):\n",
        "    for sentence in self.text.strip().split('\\n'):\n",
        "      yield self.word_tokenizer(sentence)\n",
        "\n",
        "  def build_vocab(self):\n",
        "    v = build_vocab_from_iterator(self.get_tokens(),\n",
        "                                  min_freq=1,specials=['<unk>','<mask>'])\n",
        "    v.set_default_index(v['<unk>']) # index of OOV\n",
        "    self.vocab_size = len(v)\n",
        "    return v\n",
        "\n",
        "  def token_ids(self):\n",
        "    v = self.build_vocab()\n",
        "    vt = VocabTransform(v)\n",
        "    num_tokens = len(self.word_tokenizer(self.text))\n",
        "    max_seq_len = np.ceil(num_tokens/batch_size)\n",
        "    data = torch.zeros(size=(1,num_tokens))\n",
        "    data = vt(self.word_tokenizer(self.text))\n",
        "    data = torch.tensor(data,dtype=torch.int64)\n",
        "    return data.reshape(batch_size,torch.tensor(max_seq_len,dtype=torch.int64))\n",
        "\n"
      ],
      "metadata": {
        "id": "grprn0yuf5NF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Best known for the invention of Error Correcting Codes, he was a true polymath who applied his mathematical and problem-solving skills to numerous disciplines.\n",
        "Reflecting on the significant benefits I received from Hamming, I decided to develop a tribute to his legacy. There has not been a previous biography of Hamming, and the few articles about him restate known facts and assumptions and leave us with open questions.\n",
        "One thought drove me as I developed this legacy project: An individual's legacy is more than a list of their attempts and accomplishments. Their tribute should also reveal the succeeding generations they inspired and enabled and what each attempted and achieved.\n",
        "This book is a unique genre containing my version of a biography that intertwines the story \"of a life\" and a multi-player memoir with particular events and turning points recalled by those, including me, who he inspired and enabled.\n",
        "Five years of research uncovered the people, places, opportunities, events, and influences that shaped Hamming. I discovered unpublished information, stories, photographs, videos, and personal remembrances to chronicle his life, which helped me put Hamming's\n",
        "legacy in the context I wanted.The result demonstrates many exceptional qualities, including his noble pursuit of excellence and helping others. Hamming paid attention to the details, his writings continue to influence, and his guidance is a timeless gift to the world.\n",
        "This biography is part of \"\"\""
      ],
      "metadata": {
        "id": "70QkLj9ageQu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tk = Tokenizer(text)"
      ],
      "metadata": {
        "id": "GC3n-zP3t_I9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = Tk.token_ids()\n",
        "print(input_ids.shape, input_ids)"
      ],
      "metadata": {
        "id": "LMculIZuu6Eo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57913c3b-c502-4147-e91e-9197c24631a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 26]) tensor([[ 45,  23,  69,   5,  85,   7,  63,  53,  49,   2,  20, 148,   6, 139,\n",
            "         110,  29,  36,   9,  89,   3, 112, 129,   8,  96,  59,   4],\n",
            "        [120,  97,   5, 128,  44,  11, 119,  70,  10,   2,  11,  54,   8,  57,\n",
            "           6,  28,   8,   9,  13,   4, 134,  75,  95,  43,   6, 111],\n",
            "        [ 14,   7,  10,   2,   3,   5,  67,  37,  31,  78, 123,  23,  66,   3,\n",
            "          39,   3,  86, 144,  30,  99, 117,   4,  98, 137,  61,  15],\n",
            "        [ 38,  11,  58,  16,  13, 113,  35,  80,  17,  25,  13,  12,  91, 133,\n",
            "           6,  87,   7,  27,  41,   3,  32,   4,  27,  28, 127,  34],\n",
            "        [125,   5, 132,  71, 135,  22,   3,  18,   3, 149,  62,  40,   3,  33,\n",
            "           4,  16,  46,  12,   6, 142,  72,  50,  93, 145,   7,   6],\n",
            "        [ 14,  26,  84,   5, 131,   7,   6,  24,   3,   6,  92,  90,  30, 104,\n",
            "          19,   3, 140, 109, 118,  47, 136,   2,  21,  15,   2,  29],\n",
            "        [ 20,  22,   3,  18,   4,  68, 153,   7, 122, 141,   5, 105,   2, 108,\n",
            "           2, 100,   2,  19,   2,   3,  82,  26, 126,  10,   4,  11],\n",
            "        [ 60, 143,  83,   2, 130,   2, 107,   2, 146,   2,   3, 106, 121,   8,\n",
            "          48,   9,  24,   2, 150,  76,  15, 115,  10,  17,  25,  13],\n",
            "        [ 79,   5,  51,  11, 147,   4,   5, 124,  55,  88,  65, 116,   2,  21,\n",
            "           9,  94, 114,   7,  64,   3,  77, 101,   4,  10, 102,  42],\n",
            "        [  8,   5,  56,   2,   9, 152,  52,   8,  81,   2,   3,   9,  74,  12,\n",
            "           6, 138,  73,   8,   5, 151,   4,  16,  14,  12, 103,   7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We need to mask some words randomly based on the mask probability\n",
        "* The token id for the [mask] is 1\n",
        "* The function given below takes in the input ids and replaces some of the ids by 1 (token id for the [mask])\n",
        "* Since the loss is computed only over the predictions of masked tokens, we replace all non-masked input ids by -100"
      ],
      "metadata": {
        "id": "6LLxZQox6XrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getdata(ip_ids,mask_token_id,mask_prob=0.2):\n",
        "  masked_ids = copy.deepcopy(ip_ids)\n",
        "  mask_random_idx = torch.randn_like(ip_ids,dtype=torch.float64)>(1-mask_prob)\n",
        "  masked_ids[mask_random_idx]=mask_token_id\n",
        "  labels = copy.deepcopy(ip_ids)\n",
        "  neg_mask = ~mask_random_idx\n",
        "  labels[neg_mask]=torch.tensor(-100)\n",
        "  return (masked_ids,labels,mask_random_idx)"
      ],
      "metadata": {
        "id": "Cpo-UM-Dvu7b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_token_id = torch.tensor([1],dtype=torch.int64)\n",
        "x,y,mask_mtx = getdata(input_ids,mask_token_id)\n",
        "print(x[0,:],'\\n',y[0,:], '\\n', mask_mtx[0:])"
      ],
      "metadata": {
        "id": "nc9TtOBmxAiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948b8d67-7759-46c3-8dbd-e520342bdc7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 45,   1,  69,   5,  85,   7,  63,  53,  49,   1,   1, 148,   6,   1,\n",
            "        110,  29,  36,   1,  89,   3, 112,   1,   8,  96,  59,   4]) \n",
            " tensor([-100,   23, -100, -100, -100, -100, -100, -100, -100,    2,   20, -100,\n",
            "        -100,  139, -100, -100, -100,    9, -100, -100, -100,  129, -100, -100,\n",
            "        -100, -100]) \n",
            " tensor([[False,  True, False, False, False, False, False, False, False,  True,\n",
            "          True, False, False,  True, False, False, False,  True, False, False,\n",
            "         False,  True, False, False, False, False],\n",
            "        [False, False,  True, False,  True, False,  True, False, False, False,\n",
            "         False, False,  True, False,  True, False, False, False, False,  True,\n",
            "          True, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False,  True,  True, False,\n",
            "         False,  True, False, False, False,  True,  True, False, False, False,\n",
            "         False, False,  True, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True, False, False,  True, False, False, False, False, False,\n",
            "         False, False, False, False, False, False],\n",
            "        [ True,  True,  True, False, False, False, False, False, False, False,\n",
            "         False, False,  True, False, False,  True, False, False, False, False,\n",
            "         False, False, False,  True, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True, False,  True,  True, False, False, False, False,\n",
            "          True, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False,  True, False, False,  True,\n",
            "         False, False,  True, False, False, False, False,  True, False, False,\n",
            "         False, False, False,  True, False, False],\n",
            "        [ True, False,  True, False, False, False, False,  True, False, False,\n",
            "         False,  True, False, False, False, False, False, False, False, False,\n",
            "          True, False, False, False, False,  True],\n",
            "        [False, False, False, False, False,  True, False, False, False,  True,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False,  True,  True, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now we have our inputs and labels stored in x and y,respectively\n",
        "* It is always good to test the implementation by displaying the input sentence with masked tokens"
      ],
      "metadata": {
        "id": "1DmbfCrB78OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = Tk.build_vocab()\n",
        "words = []\n",
        "for idx in x[0,:]:\n",
        "  words.append(v.vocab.get_itos()[idx.item()])\n",
        "print(' '.join(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7ikvzvxG91S",
        "outputId": "c7990355-980d-4f22-cd45-8ad3fcd5a2b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best <mask> for the invention of error correcting codes <mask> <mask> was a <mask> polymath who applied <mask> mathematical and problem-solving <mask> to numerous disciplines .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Also display the words that are masked"
      ],
      "metadata": {
        "id": "dHn0Qj5a8UKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for idx in y[0,:]:\n",
        "  if idx != -100:\n",
        "    words.append(v.vocab.get_itos()[idx.item()])\n",
        "print(' '.join(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKR0ODDwIC42",
        "outputId": "cd441646-1ae4-48d8-d676-29c366c0eabb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "known , he true his skills\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "6xQJpejJyO3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = Tk.vocab_size\n",
        "seq_len = x.shape[1]\n",
        "embed_dim = 32\n",
        "dmodel = embed_dim\n",
        "dq = torch.tensor(4)\n",
        "dk = torch.tensor(4)\n",
        "dv = torch.tensor(4)\n",
        "heads = torch.tensor(8)\n",
        "d_ff = 4*dmodel"
      ],
      "metadata": {
        "id": "IStSC20XyQeS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "LkR1OK06xzOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MHA(nn.Module):\n",
        "  def __init__(self, dmodel, dq, dk, dv,heads):\n",
        "    super(MHA, self).__init__()\n",
        "    self.d_model = dmodel\n",
        "    self.heads = heads\n",
        "    self.W_q = nn.Parameter(torch.randn((heads, dmodel, dq),generator = torch.manual_seed(43)))\n",
        "    self.W_k = nn.Parameter(torch.randn((heads, dmodel, dk),generator = torch.manual_seed(44)))\n",
        "    self.W_v = nn.Parameter(torch.randn((heads, dmodel, dv),generator = torch.manual_seed(45)))\n",
        "    self.W_o = nn.Parameter(torch.randn((dmodel, dmodel),generator = torch.manual_seed(46)))\n",
        "\n",
        "  def forward(self, Q, K, V):\n",
        "    BS, T, _ = Q.shape\n",
        "    #print(Q.shape, self.W_q.shape)\n",
        "    Q = torch.einsum('BTM, HMQ -> BHTQ', Q, self.W_q)\n",
        "    K = torch.einsum('BTM, HMK -> BHTK', K, self.W_k)\n",
        "    V = torch.einsum('BTM, HMV -> BHTV', V, self.W_v)\n",
        "    attn_score = torch.matmul(F.softmax((torch.matmul(Q,torch.transpose(K, -2, -1)))/math.sqrt(dq), dim = -1), V)\n",
        "    combined_attn = attn_score.permute(0,2,1,3).contiguous().view(BS, T, -1)\n",
        "    out = torch.matmul(combined_attn, self.W_o)\n",
        "    #print(f'Output after MHMA : {out.shape}')\n",
        "    return out\n",
        "\n",
        "class FFN(nn.Module):\n",
        "  def __init__(self, dmodel, d_ff):\n",
        "    super(FFN, self).__init__()\n",
        "    self.W1 = nn.Parameter(torch.randn((dmodel, d_ff), generator = torch.manual_seed(47))) #Weights\n",
        "    self.b1 = nn.Parameter(torch.randn((d_ff), generator = torch.manual_seed(10))) #Bias\n",
        "    self.W2 = nn.Parameter(torch.randn((d_ff, dmodel), generator = torch.manual_seed(48))) #Weights\n",
        "    self.b2 = nn.Parameter(torch.randn((dmodel), generator = torch.manual_seed(10))) #Bias\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.einsum('BTM, MH -> BTH', x, self.W1) + self.b1\n",
        "    out = self.relu(out)\n",
        "    out = torch.einsum('BTM, MH -> BTH', out, self.W2) + self.b2\n",
        "    #print(f'Output after FFN : {out.shape}')\n",
        "    return out\n",
        "\n",
        "\n",
        "class Prediction(nn.Module):\n",
        "  def __init__(self, dmodel, trgt_vocab_size):\n",
        "    super(Prediction, self).__init__()\n",
        "    self.W = nn.Parameter(torch.randn((dmodel, trgt_vocab_size), generator = torch.manual_seed(49)))\n",
        "    self.b = nn.Parameter(torch.randn((trgt_vocab_size), generator = torch.manual_seed(10)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.matmul(x, self.W) + self.b\n",
        "    #print(f'Output shape after Output Layer: {out.shape}')\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self,d_model, max_seq_len = 512):\n",
        "      super(PositionalEncoding, self).__init__()\n",
        "\n",
        "      #compute it in the log space\n",
        "      pe = torch.zeros(max_seq_len, dmodel)\n",
        "      position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "      div_term = torch.exp(torch.arange(0, dmodel, 2).float() * (-torch.log(torch.tensor(10000.0)) / dmodel))\n",
        "      pe[:, 0::2] = torch.sin(position * div_term)\n",
        "      pe[:, 1::2] = torch.cos(position * div_term)\n",
        "      self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "  def forward(self, x):\n",
        "      # add positional embedding\n",
        "      x = x + self.pe[:, :x.size(1)]\n",
        "      return x\n",
        "\n",
        "\n",
        "class Embed(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_dim):\n",
        "    super(Embed,self).__init__()\n",
        "    self.embed = nn.Embedding(num_embeddings = vocab_size, embedding_dim = dmodel, _weight = torch.randn((vocab_size, dmodel), generator=torch.manual_seed(70)) ) #None # seed 70\n",
        "    self.pe = PositionalEncoding(dmodel)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.pe(self.embed(x))\n",
        "    return out\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self,dmodel,dq,dk,dv,d_ff,heads):\n",
        "    super(EncoderLayer,self).__init__()\n",
        "    self.mha = MHA(dmodel,dq,dk,dv,heads)\n",
        "    self.layer_norm_1 = torch.nn.LayerNorm(dmodel)\n",
        "    self.layer_norm_2 = torch.nn.LayerNorm(dmodel)\n",
        "    self.ffn = FFN(dmodel,d_ff)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.mha(x,x,x)\n",
        "    out = self.layer_norm_1(out+x)\n",
        "    out = self.layer_norm_2(self.ffn(out)+out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "lwKEEtfXxWg0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,dmodel,dq,dk,dv,d_ff,heads,num_layers=1):\n",
        "    super(BERT,self).__init__()\n",
        "    self.embed_lookup = Embed(vocab_size,embed_dim)\n",
        "    self.enc_layers = nn.ModuleList(copy.deepcopy(EncoderLayer(dmodel,dq,dk,dv,d_ff,heads)) for i in range(num_layers))\n",
        "    self.predict = Prediction(dmodel,vocab_size)\n",
        "\n",
        "  def forward(self,input_ids):\n",
        "    x = self.embed_lookup(input_ids)\n",
        "    for enc_layer in self.enc_layers:\n",
        "      x = enc_layer(x)\n",
        "    out = self.predict(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "uSzvePtJyvWj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERT(vocab_size,dmodel,dq,dk,dv,d_ff,heads,num_layers=1)\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "gwapWxHv2Djs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "HxBH1VRCB2IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(token_ids, labels, epochs=1000):\n",
        "    loss_trace = []\n",
        "    for epoch in range(epochs):\n",
        "        out = model(token_ids)\n",
        "        out = out.view(-1, vocab_size)\n",
        "\n",
        "        target = labels.view(-1)\n",
        "        valid_mask = target != -100  # Mask to exclude padding tokens\n",
        "        target = target[valid_mask]\n",
        "        out = out[valid_mask]\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(out, target.type(torch.LongTensor))\n",
        "        loss_trace.append(loss.item())\n",
        "\n",
        "        # Print loss every 1000 epochs\n",
        "        if (epoch + 1) % 1000 == 0:\n",
        "            print(f'Epoch: {epoch + 1} Loss: {loss.item()}')\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # Visualize loss\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, epochs + 1), loss_trace, label='Training Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "an64oZq96wvP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(x,y,20000)"
      ],
      "metadata": {
        "id": "GgFE9rBKCEn7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "outputId": "c86cc258-ed3b-4cf9-c70a-21df94813add"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1000 Loss: 0.33711302280426025\n",
            "Epoch: 2000 Loss: 0.0641457810997963\n",
            "Epoch: 3000 Loss: 0.025812903419137\n",
            "Epoch: 4000 Loss: 0.015111851505935192\n",
            "Epoch: 5000 Loss: 0.01032387837767601\n",
            "Epoch: 6000 Loss: 0.007766495458781719\n",
            "Epoch: 7000 Loss: 0.006170845590531826\n",
            "Epoch: 8000 Loss: 0.00509690772742033\n",
            "Epoch: 9000 Loss: 0.004323770757764578\n",
            "Epoch: 10000 Loss: 0.0037424706388264894\n",
            "Epoch: 11000 Loss: 0.00328437308780849\n",
            "Epoch: 12000 Loss: 0.0029226928018033504\n",
            "Epoch: 13000 Loss: 0.0026294225826859474\n",
            "Epoch: 14000 Loss: 0.002385159954428673\n",
            "Epoch: 15000 Loss: 0.0021803309209644794\n",
            "Epoch: 16000 Loss: 0.002006445312872529\n",
            "Epoch: 17000 Loss: 0.001857340452261269\n",
            "Epoch: 18000 Loss: 0.0017277722945436835\n",
            "Epoch: 19000 Loss: 0.0016141940141096711\n",
            "Epoch: 20000 Loss: 0.0015134247951209545\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The loss have came down around 0.0015 after 20000 epochs.\n",
        "* Let us predict the masked tokens for all the samples in the tiny dataset"
      ],
      "metadata": {
        "id": "bm6javO6DfOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  predictions = torch.argmax(model(x),dim=-1)"
      ],
      "metadata": {
        "id": "sHyMJYvVCEu2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = Tk.build_vocab()\n",
        "masked_words = []\n",
        "predicted_words=[]\n",
        "for index,idx in enumerate(y.flatten()):\n",
        "  # to display only the masked tokens\n",
        "  if idx != -100:\n",
        "    masked_words.append(v.vocab.get_itos()[idx.item()])\n",
        "    predicted_words.append(v.vocab.get_itos()[predictions.flatten()[index].item()])\n",
        "print('Masked Words: ')\n",
        "print(' '.join(masked_words))\n",
        "print('Predicted Words: ')\n",
        "print(' '.join(predicted_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90vsv_m8J57q",
        "outputId": "6a1c508a-3729-44bd-cb33-c57caed974f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masked Words: \n",
            "known , he true his skills the benefits received to a . there articles about known and leave one is a reveal the succeeding and this version with events and those years uncovered , events hamming discovered information , personal me legacy . many continue to\n",
            "Predicted Words: \n",
            "known , he true his skills the benefits received to a . there articles about known and leave one is a reveal the succeeding and this version with events and those years uncovered , events hamming discovered information , personal me legacy . many continue to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUIaODYLrATi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}